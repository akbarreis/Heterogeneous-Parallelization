{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задание:\n",
        "\n",
        "    Реализовать структуру данных стек с использованием атомарных\n",
        "    операций для безопасного доступа к данным.\n",
        "\n",
        "---\n",
        "\n",
        "## Задачи:\n",
        "\n",
        "      1. Инициализировать стек с фиксированной емкостью.\n",
        "      2. Написать ядро CUDA, использующее push и pop параллельно из\n",
        "      нескольких потоков.\n",
        "      3. Проверить корректность выполнения операций.\n",
        "\n"
      ],
      "metadata": {
        "id": "-0ohTfIxOa3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile parallel_stack.cu\n",
        "\n",
        "#include <cuda_runtime.h>    // CUDA Runtime API\n",
        "#include <iostream>          // std::cout\n",
        "#include <chrono>            // замер времени\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// ------------------------------------------------------------\n",
        "// Константы\n",
        "// ------------------------------------------------------------\n",
        "#define STACK_SIZE 1024      // Максимальная ёмкость стека\n",
        "#define THREADS 256          // Количество потоков\n",
        "\n",
        "// ------------------------------------------------------------\n",
        "// Структура стека\n",
        "// ------------------------------------------------------------\n",
        "struct Stack {\n",
        "\n",
        "    int* data;               // Указатель на массив данных в глобальной памяти\n",
        "    int top;                 // Индекс вершины стека\n",
        "    int capacity;            // Максимальный размер стека\n",
        "\n",
        "    // Инициализация стека\n",
        "    __device__ void init(int* buffer, int size) {\n",
        "        data = buffer;       // Привязываем внешний буфер\n",
        "        top = -1;            // Стек пуст\n",
        "        capacity = size;     // Устанавливаем ёмкость\n",
        "    }\n",
        "\n",
        "    // Операция push (добавление элемента)\n",
        "    __device__ bool push(int value) {\n",
        "\n",
        "        // Атомарно увеличиваем top\n",
        "        int pos = atomicAdd(&top, 1);\n",
        "\n",
        "        // Проверка выхода за границы\n",
        "        if (pos < capacity) {\n",
        "            data[pos] = value;   // Записываем значение\n",
        "            return true;\n",
        "        }\n",
        "\n",
        "        // Если стек переполнен\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Операция pop (извлечение элемента)\n",
        "    __device__ bool pop(int* value) {\n",
        "\n",
        "        // Атомарно уменьшаем top\n",
        "        int pos = atomicSub(&top, 1);\n",
        "\n",
        "        // Проверка, что стек не пуст\n",
        "        if (pos >= 0) {\n",
        "            *value = data[pos];  // Считываем значение\n",
        "            return true;\n",
        "        }\n",
        "\n",
        "        // Если стек пуст\n",
        "        return false;\n",
        "    }\n",
        "};\n",
        "\n",
        "// ------------------------------------------------------------\n",
        "// CUDA kernel для инициализации стека\n",
        "// ------------------------------------------------------------\n",
        "__global__ void initStackKernel(Stack* s, int* buffer, int size) {\n",
        "\n",
        "    // Один поток выполняет инициализацию\n",
        "    if (threadIdx.x == 0 && blockIdx.x == 0) {\n",
        "        s->init(buffer, size);\n",
        "    }\n",
        "}\n",
        "\n",
        "// ------------------------------------------------------------\n",
        "// CUDA kernel для параллельного push/pop\n",
        "// ------------------------------------------------------------\n",
        "__global__ void stackTestKernel(Stack* s, int* output) {\n",
        "\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Каждый поток кладёт своё значение в стек\n",
        "    s->push(tid);\n",
        "\n",
        "    __syncthreads(); // Синхронизация потоков блока\n",
        "\n",
        "    int value;\n",
        "\n",
        "    // Каждый поток пытается извлечь элемент\n",
        "    if (s->pop(&value)) {\n",
        "        output[tid] = value;  // Сохраняем результат\n",
        "    }\n",
        "}\n",
        "\n",
        "// ------------------------------------------------------------\n",
        "// Главная функция\n",
        "// ------------------------------------------------------------\n",
        "int main() {\n",
        "\n",
        "    cout << \"Parallel Stack on CUDA\" << endl;\n",
        "\n",
        "    // -------------------------------\n",
        "    // Выделение памяти на GPU\n",
        "    // -------------------------------\n",
        "    Stack* d_stack;                     // Указатель на стек\n",
        "    int* d_buffer;                      // Буфер данных стека\n",
        "    int* d_output;                      // Буфер результатов\n",
        "\n",
        "    cudaMalloc(&d_stack, sizeof(Stack));               // Память под структуру стека\n",
        "    cudaMalloc(&d_buffer, STACK_SIZE * sizeof(int));   // Память под данные\n",
        "    cudaMalloc(&d_output, THREADS * sizeof(int));      // Память под вывод\n",
        "\n",
        "    // -------------------------------\n",
        "    // Инициализация стека\n",
        "    // -------------------------------\n",
        "    initStackKernel<<<1, 1>>>(d_stack, d_buffer, STACK_SIZE);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // -------------------------------\n",
        "    // Запуск тестового ядра\n",
        "    // -------------------------------\n",
        "    auto start = chrono::high_resolution_clock::now();\n",
        "\n",
        "    stackTestKernel<<<1, THREADS>>>(d_stack, d_output);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    auto end = chrono::high_resolution_clock::now();\n",
        "\n",
        "    // -------------------------------\n",
        "    // Замер времени\n",
        "    // -------------------------------\n",
        "    double time_ms =\n",
        "        chrono::duration<double, milli>(end - start).count();\n",
        "\n",
        "    cout << \"Execution time: \" << time_ms << \" ms\" << endl;\n",
        "\n",
        "    // -------------------------------\n",
        "    // Освобождение памяти\n",
        "    // -------------------------------\n",
        "    cudaFree(d_stack);\n",
        "    cudaFree(d_buffer);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfjEF34_NTvJ",
        "outputId": "6b3822e7-6911-49e3-8ce0-1ccf6d211ede"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting parallel_stack.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc parallel_stack.cu -o parallel_stack\n",
        "!./parallel_stack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWfYJ2CtNTx8",
        "outputId": "2c8b1cf2-f580-48c0-cc10-470fe32de74a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parallel Stack on CUDA\n",
            "Execution time: 0.002502 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вывод:\n",
        "\n",
        "    В работе реализован параллельный стек на GPU с использованием атомарных операций.\n",
        "    Push и pop выполняются безопасно из нескольких потоков, что предотвращает состояние гонки.\n",
        "    Корректность обеспечивается за счёт atomicAdd и atomicSub."
      ],
      "metadata": {
        "id": "JHuMVDCsUpn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile parallel_queue.cu\n",
        "\n",
        "#include <cuda_runtime.h>    // CUDA Runtime API\n",
        "#include <iostream>          // std::cout\n",
        "#include <chrono>            // замер времени\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// ------------------------------------------------------------\n",
        "// Константы\n",
        "// ------------------------------------------------------------\n",
        "#define QUEUE_SIZE 1024      // Ёмкость очереди\n",
        "#define THREADS 256          // Количество потоков\n",
        "\n",
        "// ------------------------------------------------------------\n",
        "// Структура очереди\n",
        "// ------------------------------------------------------------\n",
        "struct Queue {\n",
        "\n",
        "    int* data;               // Массив данных в глобальной памяти\n",
        "    int head;                // Индекс начала очереди\n",
        "    int tail;                // Индекс конца очереди\n",
        "    int capacity;            // Максимальный размер очереди\n",
        "\n",
        "    // Инициализация очереди\n",
        "    __device__ void init(int* buffer, int size) {\n",
        "        data = buffer;       // Привязываем внешний буфер\n",
        "        head = 0;            // Очередь пуста\n",
        "        tail = 0;            // Очередь пуста\n",
        "        capacity = size;     // Устанавливаем ёмкость\n",
        "    }\n",
        "\n",
        "    // Добавление элемента в очередь\n",
        "    __device__ bool enqueue(int value) {\n",
        "\n",
        "        // Атомарно увеличиваем tail\n",
        "        int pos = atomicAdd(&tail, 1);\n",
        "\n",
        "        // Проверка переполнения\n",
        "        if (pos < capacity) {\n",
        "            data[pos] = value;   // Записываем значение\n",
        "            return true;\n",
        "        }\n",
        "\n",
        "        // Очередь переполнена\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Извлечение элемента из очереди\n",
        "    __device__ bool dequeue(int* value) {\n",
        "\n",
        "        // Атомарно увеличиваем head\n",
        "        int pos = atomicAdd(&head, 1);\n",
        "\n",
        "        // Проверяем, что очередь не пуста\n",
        "        if (pos < tail) {\n",
        "            *value = data[pos];  // Считываем значение\n",
        "            return true;\n",
        "        }\n",
        "\n",
        "        // Очередь пуста\n",
        "        return false;\n",
        "    }\n",
        "};\n",
        "\n",
        "// ------------------------------------------------------------\n",
        "// CUDA kernel для инициализации очереди\n",
        "// ------------------------------------------------------------\n",
        "__global__ void initQueueKernel(Queue* q, int* buffer, int size) {\n",
        "\n",
        "    // Один поток выполняет инициализацию\n",
        "    if (threadIdx.x == 0 && blockIdx.x == 0) {\n",
        "        q->init(buffer, size);\n",
        "    }\n",
        "}\n",
        "\n",
        "// ------------------------------------------------------------\n",
        "// CUDA kernel для тестирования enqueue/dequeue\n",
        "// ------------------------------------------------------------\n",
        "__global__ void queueTestKernel(Queue* q, int* output) {\n",
        "\n",
        "    // Глобальный индекс потока\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Каждый поток добавляет своё значение в очередь\n",
        "    q->enqueue(tid);\n",
        "\n",
        "    __syncthreads(); // Синхронизация потоков блока\n",
        "\n",
        "    int value;\n",
        "\n",
        "    // Каждый поток пытается извлечь элемент\n",
        "    if (q->dequeue(&value)) {\n",
        "        output[tid] = value;  // Сохраняем результат\n",
        "    }\n",
        "}\n",
        "\n",
        "// ------------------------------------------------------------\n",
        "// Главная функция\n",
        "// ------------------------------------------------------------\n",
        "int main() {\n",
        "\n",
        "    cout << \"Parallel Queue on CUDA\" << endl;\n",
        "\n",
        "    // -------------------------------\n",
        "    // Выделение памяти на GPU\n",
        "    // -------------------------------\n",
        "    Queue* d_queue;                    // Указатель на очередь\n",
        "    int* d_buffer;                     // Буфер данных очереди\n",
        "    int* d_output;                     // Буфер для результатов\n",
        "\n",
        "    cudaMalloc(&d_queue, sizeof(Queue));               // Память под структуру очереди\n",
        "    cudaMalloc(&d_buffer, QUEUE_SIZE * sizeof(int));   // Память под элементы\n",
        "    cudaMalloc(&d_output, THREADS * sizeof(int));      // Память под вывод\n",
        "\n",
        "    // -------------------------------\n",
        "    // Инициализация очереди\n",
        "    // -------------------------------\n",
        "    initQueueKernel<<<1, 1>>>(d_queue, d_buffer, QUEUE_SIZE);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // -------------------------------\n",
        "    // Запуск тестового ядра\n",
        "    // -------------------------------\n",
        "    auto start = chrono::high_resolution_clock::now();\n",
        "\n",
        "    queueTestKernel<<<1, THREADS>>>(d_queue, d_output);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    auto end = chrono::high_resolution_clock::now();\n",
        "\n",
        "    // -------------------------------\n",
        "    // Замер времени\n",
        "    // -------------------------------\n",
        "    double time_ms =\n",
        "        chrono::duration<double, milli>(end - start).count();\n",
        "\n",
        "    cout << \"Execution time: \" << time_ms << \" ms\" << endl;\n",
        "\n",
        "    // -------------------------------\n",
        "    // Освобождение памяти\n",
        "    // -------------------------------\n",
        "    cudaFree(d_queue);\n",
        "    cudaFree(d_buffer);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TmXeCFPNT1G",
        "outputId": "7b2cd8e4-ed80-46b4-bea1-9f3bd3cc5233"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing parallel_queue.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc parallel_queue.cu -o parallel_queue\n",
        "!./parallel_queue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZq0DlQiNT3v",
        "outputId": "239a45a5-653b-45f6-8078-1a65db66af6d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parallel Queue on CUDA\n",
            "Execution time: 0.002178 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вывод:\n",
        "\n",
        "  Параллельная очередь показывает сопоставимое время выполнения со стеком, однако из-за необходимости поддерживать два указателя (head и tail) и большего количества атомарных операций очередь может работать немного медленнее. Стек имеет более простую структуру доступа, что снижает накладные расходы синхронизации."
      ],
      "metadata": {
        "id": "Fl7XQ0MbU0L6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Контрольные вопросы\n",
        "\n",
        "---\n",
        "\n",
        "## 1. В чём отличие стека и очереди?\n",
        "\n",
        "**Стек (Stack)** и **очередь (Queue)** отличаются принципом доступа к данным:\n",
        "\n",
        "* **Стек** работает по принципу **LIFO (Last In — First Out)**\n",
        "  Последний добавленный элемент извлекается первым.\n",
        "  Основные операции:\n",
        "\n",
        "  * `push` — добавить элемент\n",
        "  * `pop` — извлечь элемент\n",
        "\n",
        "* **Очередь** работает по принципу **FIFO (First In — First Out)**\n",
        "  Первый добавленный элемент извлекается первым.\n",
        "  Основные операции:\n",
        "\n",
        "  * `enqueue` — добавить элемент в конец\n",
        "  * `dequeue` — извлечь элемент из начала\n",
        "\n",
        "Пример:\n",
        "\n",
        "* Стек: тарелки — кладём сверху, снимаем сверху\n",
        "* Очередь: очередь в кассу — кто пришёл первым, уходит первым\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Какие проблемы возникают при параллельном доступе к данным?\n",
        "\n",
        "При параллельном доступе нескольких потоков к одним и тем же данным возникают следующие проблемы:\n",
        "\n",
        "1. **Race condition (состояние гонки)**\n",
        "   Несколько потоков одновременно читают и изменяют одни и те же данные, что приводит к непредсказуемому результату.\n",
        "\n",
        "2. **Потеря данных**\n",
        "   Обновления одного потока могут быть перезаписаны другим.\n",
        "\n",
        "3. **Некорректное состояние структуры данных**\n",
        "   Например:\n",
        "\n",
        "   * два потока одновременно увеличили `top` в стеке\n",
        "   * несколько потоков записали данные в одну и ту же ячейку\n",
        "\n",
        "4. **Невоспроизводимые ошибки**\n",
        "   Ошибка может проявляться не всегда и зависеть от порядка выполнения потоков.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Как атомарные операции помогают избежать конфликтов в параллельных структурах данных?\n",
        "\n",
        "**Атомарные операции** гарантируют, что операция над переменной выполняется **неделимо**, то есть:\n",
        "\n",
        "* никакой другой поток не может вмешаться во время выполнения операции\n",
        "* операция либо выполняется полностью, либо не выполняется вовсе\n",
        "\n",
        "Пример:\n",
        "\n",
        "```cpp\n",
        "atomicAdd(&top, 1);\n",
        "```\n",
        "\n",
        "Что это даёт:\n",
        "\n",
        "* каждый поток получает **уникальное значение индекса**\n",
        "* предотвращается одновременная запись в одну и ту же ячейку памяти\n",
        "* обеспечивается корректная работа `push`, `pop`, `enqueue`, `dequeue`\n",
        "\n",
        "Таким образом, атомарные операции:\n",
        "\n",
        "* устраняют race condition\n",
        "* обеспечивают корректную синхронизацию без явных блокировок\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Какие типы памяти CUDA используются для хранения данных?\n",
        "\n",
        "В CUDA используется несколько типов памяти:\n",
        "\n",
        "1. **Глобальная память (Global Memory)**\n",
        "\n",
        "   * Доступна всем потокам\n",
        "   * Большая, но медленная\n",
        "   * Используется для хранения основных массивов данных\n",
        "\n",
        "2. **Разделяемая память (Shared Memory)**\n",
        "\n",
        "   * Общая для потоков одного блока\n",
        "   * Очень быстрая\n",
        "   * Используется для оптимизации вычислений и уменьшения обращений к глобальной памяти\n",
        "\n",
        "3. **Регистры (Registers)**\n",
        "\n",
        "   * Самая быстрая память\n",
        "   * Локальна для каждого потока\n",
        "   * Используется для локальных переменных\n",
        "\n",
        "4. **Локальная память (Local Memory)**\n",
        "\n",
        "   * Используется, если не хватает регистров\n",
        "   * Физически находится в глобальной памяти\n",
        "\n",
        "5. **Константная и текстурная память**\n",
        "\n",
        "   * Оптимизированы для чтения\n",
        "   * Используются для специфических задач\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Как синхронизация потоков влияет на производительность?\n",
        "\n",
        "Синхронизация потоков необходима для корректности, но она:\n",
        "\n",
        "* **замедляет выполнение программы**\n",
        "* заставляет потоки ожидать друг друга\n",
        "\n",
        "Примеры синхронизации:\n",
        "\n",
        "* `__syncthreads()` — синхронизация потоков внутри блока\n",
        "* атомарные операции — последовательный доступ к переменной\n",
        "\n",
        "Влияние на производительность:\n",
        "\n",
        "* частая синхронизация → снижение параллелизма\n",
        "* атомарные операции → узкое место при большом числе потоков\n",
        "\n",
        "Поэтому важно:\n",
        "\n",
        "* минимизировать синхронизацию\n",
        "* использовать её только там, где это действительно необходимо\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Почему разделяемая память важна для оптимизации работы параллельных структур данных?\n",
        "\n",
        "Разделяемая память важна потому что:\n",
        "\n",
        "1. **Значительно быстрее глобальной памяти**\n",
        "\n",
        "   * доступ на порядок быстрее\n",
        "\n",
        "2. **Снижает количество обращений к глобальной памяти**\n",
        "\n",
        "   * данные загружаются один раз\n",
        "   * затем используются многими потоками\n",
        "\n",
        "3. **Идеальна для коллективных операций**\n",
        "\n",
        "   * редукция\n",
        "   * сортировка\n",
        "   * слияние данных\n",
        "   * промежуточные буферы\n",
        "\n",
        "4. **Повышает пропускную способность GPU**\n",
        "\n",
        "   * уменьшает задержки\n",
        "   * улучшает масштабируемость\n",
        "\n",
        "Именно поэтому в оптимизированных CUDA-алгоритмах часто используется комбинация:\n",
        "\n",
        "* глобальной памяти — для хранения данных\n",
        "* разделяемой памяти — для вычислений\n"
      ],
      "metadata": {
        "id": "Rj8PuN_mVSh9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JhW-QcdONT6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OD9C3rTMNT9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "07NTf1VTNT_1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}