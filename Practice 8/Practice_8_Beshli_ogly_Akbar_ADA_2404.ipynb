{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 1: Реализация обработки массива на CPU с использованием OpenMP\n",
        "\n",
        "    1. Создайте массив данных размером `N` (например, `N = 1 000 000`).\n",
        "    2. Реализуйте функцию для обработки массива на CPU с использованием\n",
        "    OpenMP. Например, умножьте каждый элемент массива на 2.\n",
        "    3. Замерьте время выполнения обработки на CPU."
      ],
      "metadata": {
        "id": "D5Whfzt0hrSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task1.cpp\n",
        "\n",
        "#include <iostream>     // Для вывода в консоль\n",
        "#include <vector>       // Для использования std::vector\n",
        "#include <chrono>       // Для замера времени\n",
        "#include <omp.h>        // Заголовок OpenMP\n",
        "\n",
        "int main() {\n",
        "\n",
        "    // ------------------------------\n",
        "    // 1. Создание массива данных\n",
        "    // ------------------------------\n",
        "    const int N = 1000000;             // Размер массива\n",
        "    std::vector<int> data(N, 1);       // Создаем массив размером N, инициализируем единицами\n",
        "\n",
        "    // ------------------------------\n",
        "    // 2. Замер времени начала\n",
        "    // ------------------------------\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // ------------------------------\n",
        "    // 3. Параллельная обработка массива с помощью OpenMP\n",
        "    // ------------------------------\n",
        "    #pragma omp parallel for           // Директива OpenMP: разделить цикл на потоки\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        data[i] *= 2;                  // Каждый элемент умножаем на 2\n",
        "    }\n",
        "\n",
        "    // ------------------------------\n",
        "    // 4. Замер времени конца\n",
        "    // ------------------------------\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // ------------------------------\n",
        "    // 5. Вычисление и вывод времени выполнения\n",
        "    // ------------------------------\n",
        "    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);\n",
        "    std::cout << \"Время выполнения на CPU с OpenMP: \"\n",
        "              << duration.count() << \" мс\" << std::endl;\n",
        "\n",
        "    // ------------------------------\n",
        "    // 6. Проверка результата (необязательная)\n",
        "    // ------------------------------\n",
        "    bool correct = true;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        if (data[i] != 2) {            // Все элементы должны быть равны 2\n",
        "            correct = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    std::cout << \"Проверка корректности: \"\n",
        "              << (correct ? \"OK\" : \"ERROR\") << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRwsroL7goOQ",
        "outputId": "5fd22e39-23ec-4e88-9870-4789a4570872"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing task1.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ -O2 task1.cpp -o task1\n",
        "!./task1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxVPlwo6goQt",
        "outputId": "3e090709-f959-47f4-8763-99433dcdfbab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время выполнения на CPU с OpenMP: 0 мс\n",
            "Проверка корректности: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Результаты выполнения задания 1 (обработка массива на CPU с использованием OpenMP):\n",
        "\n",
        "    Был создан массив из 1 000 000 элементов, каждый элемент изначально равен 1.\n",
        "\n",
        "    С помощью OpenMP все элементы массива были умножены на 2 параллельно несколькими потоками CPU.\n",
        "\n",
        "    Время выполнения операции на CPU оказалось 0 мс, что объясняется малым объёмом данных и высокой скоростью современных процессоров.\n",
        "\n",
        "    Проверка корректности обработки показала, что все элементы массива равны 2, то есть операция выполнена правильно.\n",
        "\n",
        "# Вывод:\n",
        "\n",
        "Задача продемонстрировала работу OpenMP для параллельной обработки массивов на CPU. Даже при минимальных операциях, использование многопоточности позволяет эффективно распределять нагрузку, хотя при маленьких объёмах данных реальное время выполнения может быть слишком малым для измерения. Для более наглядной демонстрации ускорения следует использовать массивы большего размера или более сложные вычисления."
      ],
      "metadata": {
        "id": "ggx2rue0iM1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 2. Реализация обработки массива на GPU с использованием CUDA\n",
        "\n",
        "    1. Скопируйте массив данных на GPU.\n",
        "    2. Реализуйте ядро CUDA для обработки массива на GPU. Например, умножьте\n",
        "    каждый элемент массива на 2.\n",
        "    3. Скопируйте обработанные данные обратно на CPU.\n",
        "    4. Замерьте время выполнения обработки на GPU."
      ],
      "metadata": {
        "id": "WD_rHXEejFXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task2.cu\n",
        "\n",
        "#include <iostream>         // Для вывода в консоль\n",
        "#include <chrono>           // Для замера времени\n",
        "#include <cuda_runtime.h>   // Основной заголовок CUDA\n",
        "\n",
        "// ------------------------------------------------------------\n",
        "// CUDA ядро для обработки массива\n",
        "// Каждый поток обрабатывает один элемент массива\n",
        "// ------------------------------------------------------------\n",
        "__global__ void multiply_by_two(int* data, int N) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x; // Вычисляем глобальный индекс потока\n",
        "    if (idx < N) {                                  // Проверка, чтобы не выйти за пределы массива\n",
        "        data[idx] *= 2;                             // Умножаем элемент на 2\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "    // ------------------------------\n",
        "    // 1. Создание массива данных\n",
        "    // ------------------------------\n",
        "    const int N = 1000000;                          // Размер массива\n",
        "    int* data;                                      // Указатель на массив в Unified Memory (CPU+GPU)\n",
        "\n",
        "    cudaMallocManaged(&data, N * sizeof(int));      // Выделяем управляемую память, доступную CPU и GPU\n",
        "\n",
        "    // Инициализируем массив единицами\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        data[i] = 1;\n",
        "    }\n",
        "\n",
        "    // ------------------------------\n",
        "    // 2. Конфигурация ядра CUDA\n",
        "    // ------------------------------\n",
        "    int threadsPerBlock = 256;                                         // Потоки в одном блоке\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;   // Количество блоков для полного покрытия массива\n",
        "\n",
        "    // ------------------------------\n",
        "    // 3. Замер времени выполнения GPU\n",
        "    // ------------------------------\n",
        "    cudaEvent_t start, stop;                   // События CUDA для точного измерения времени\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // ------------------------------\n",
        "    // 4. Запуск ядра на GPU\n",
        "    // ------------------------------\n",
        "    multiply_by_two<<<blocksPerGrid, threadsPerBlock>>>(data, N);\n",
        "    cudaDeviceSynchronize();                    // Ждем завершения всех потоков\n",
        "\n",
        "    // ------------------------------\n",
        "    // 5. Замер времени окончания GPU\n",
        "    // ------------------------------\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop); // Время в миллисекундах\n",
        "\n",
        "    // ------------------------------\n",
        "    // 6. Проверка корректности результата\n",
        "    // ------------------------------\n",
        "    bool correct = true;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        if (data[i] != 2) {                     // Все элементы должны быть равны 2\n",
        "            correct = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // ------------------------------\n",
        "    // 7. Вывод результатов\n",
        "    // ------------------------------\n",
        "    std::cout << \"Время выполнения на GPU: \" << milliseconds << \" мс\" << std::endl;\n",
        "    std::cout << \"Проверка корректности: \" << (correct ? \"OK\" : \"ERROR\") << std::endl;\n",
        "\n",
        "    // ------------------------------\n",
        "    // 8. Очистка памяти GPU\n",
        "    // ------------------------------\n",
        "    cudaFree(data);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqQ7CouOgoTF",
        "outputId": "f650cd4c-d5e1-45d2-c92a-93da83e14200"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting task2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc task2.cu -o task2\n",
        "!./task2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wneLUmrwgoVl",
        "outputId": "fa52ab22-8bee-4e89-bb0d-075f7a9609d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время выполнения на GPU: 7.596 мс\n",
            "Проверка корректности: ERROR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по практическому заданию (GPU, CUDA):**\n",
        "\n",
        "* Время выполнения обработки массива на GPU составило **7.596 мс**.\n",
        "* Проверка корректности результата показала **ERROR**, что означает, что после обработки на GPU некоторые элементы массива не были обработаны корректно.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4RxTiQVTjrKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 3: Гибридная обработка массива\n",
        "\n",
        "    1. Разделите массив на две части: первая половина обрабатывается на CPU,\n",
        "    вторая — на GPU.\n",
        "    2. Реализуйте гибридное приложение, которое выполняет обработку массива\n",
        "    на CPU и GPU одновременно.\n",
        "    3. Замерьте общее время выполнения гибридной обработки."
      ],
      "metadata": {
        "id": "NiIFVrJ4khCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task3_hybrid.cu\n",
        "\n",
        "#include <iostream>         // Для вывода в консоль\n",
        "#include <vector>           // Для std::vector\n",
        "#include <chrono>           // Для замера времени\n",
        "#include <omp.h>            // Для OpenMP\n",
        "#include <cuda_runtime.h>   // Для CUDA\n",
        "\n",
        "// ------------------------------------------------------------\n",
        "// CUDA ядро для обработки массива\n",
        "// Каждый поток обрабатывает один элемент массива\n",
        "// ------------------------------------------------------------\n",
        "__global__ void multiply_by_two_gpu(int* data, int N) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x; // Вычисляем глобальный индекс потока\n",
        "    if (idx < N) {                                  // Проверка границ массива\n",
        "        data[idx] *= 2;                             // Умножаем элемент на 2\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // ------------------------------\n",
        "    // 1. Создание массива данных\n",
        "    // ------------------------------\n",
        "    const int N = 1000000;                            // Размер массива\n",
        "    std::vector<int> h_data(N, 1);                    // Инициализация массива единицами\n",
        "\n",
        "    // ------------------------------\n",
        "    // 2. Разделяем массив на две части\n",
        "    // ------------------------------\n",
        "    int half = N / 2;                                 // Половина массива для CPU, половина для GPU\n",
        "\n",
        "    // ------------------------------\n",
        "    // 3. Выделение памяти GPU для второй половины\n",
        "    // ------------------------------\n",
        "    int* d_data;\n",
        "    cudaMalloc(&d_data, half * sizeof(int));          // Выделяем память для второй половины\n",
        "    cudaMemcpy(d_data, h_data.data() + half, half * sizeof(int), cudaMemcpyHostToDevice); // Копируем вторую половину на GPU\n",
        "\n",
        "    // ------------------------------\n",
        "    // 4. Конфигурация ядра CUDA\n",
        "    // ------------------------------\n",
        "    int threadsPerBlock = 256;                                         // Потоки в блоке\n",
        "    int blocksPerGrid = (half + threadsPerBlock - 1) / threadsPerBlock; // Количество блоков\n",
        "\n",
        "    // ------------------------------\n",
        "    // 5. Замер времени гибридной обработки\n",
        "    // ------------------------------\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // 5a. Обработка первой половины на CPU с OpenMP\n",
        "    #pragma omp parallel for\n",
        "    for (int i = 0; i < half; i++) {\n",
        "        h_data[i] *= 2;\n",
        "    }\n",
        "\n",
        "    // 5b. Обработка второй половины на GPU\n",
        "    multiply_by_two_gpu<<<blocksPerGrid, threadsPerBlock>>>(d_data, half);\n",
        "    cudaDeviceSynchronize(); // Ждем завершения всех потоков GPU\n",
        "\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "    float milliseconds = std::chrono::duration<float, std::milli>(end - start).count();\n",
        "\n",
        "    // ------------------------------\n",
        "    // 6. Копирование данных обратно с GPU\n",
        "    // ------------------------------\n",
        "    cudaMemcpy(h_data.data() + half, d_data, half * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // ------------------------------\n",
        "    // 7. Проверка корректности результата\n",
        "    // ------------------------------\n",
        "    bool correct = true;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        if (h_data[i] != 2) {                        // Все элементы должны быть равны 2\n",
        "            correct = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // ------------------------------\n",
        "    // 8. Вывод результатов\n",
        "    // ------------------------------\n",
        "    std::cout << \"Общее время выполнения гибридной обработки: \" << milliseconds << \" мс\" << std::endl;\n",
        "    std::cout << \"Проверка корректности: \" << (correct ? \"OK\" : \"ERROR\") << std::endl;\n",
        "\n",
        "    // ------------------------------\n",
        "    // 9. Очистка памяти GPU\n",
        "    // ------------------------------\n",
        "    cudaFree(d_data);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8Oz6f95goX-",
        "outputId": "f7a01a02-2ae4-4945-d08d-4d4630250ea2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing task3_hybrid.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc task3_hybrid.cu -o task3\n",
        "!./task3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvPI3mFugoad",
        "outputId": "69179f2d-f034-4537-9e65-ee3ba5b74f11"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Общее время выполнения гибридной обработки: 8.87387 мс\n",
            "Проверка корректности: ERROR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по практическому заданию (гибридная обработка CPU + GPU):**\n",
        "\n",
        "* Общее время выполнения обработки массива составило **8.874 мс**.\n",
        "* Проверка корректности результата показала **ERROR**, что означает, что после объединённой обработки на CPU и GPU некоторые элементы массива не были обработаны корректно.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A4tlG3haka31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 4: Анализ производительности\n",
        "\n",
        "    1. Сравните время выполнения обработки массива на CPU, GPU и в гибридном\n",
        "    режиме.\n",
        "    2. Проведите анализ производительности и определите, в каких случаях\n",
        "    гибридный подход дает наибольший выигрыш."
      ],
      "metadata": {
        "id": "zQACB0_Ukm0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Сравнение времени выполнения обработки массива**\n",
        "\n",
        "| Метод обработки       | Время выполнения (мс) | Корректность |\n",
        "| --------------------- | --------------------- | ------------ |\n",
        "| CPU (OpenMP)          | 0                     | OK           |\n",
        "| GPU (CUDA)            | 7.596                 | ERROR        |\n",
        "| Гибридный (CPU + GPU) | 8.874                 | ERROR        |\n",
        "\n",
        "---\n",
        "\n",
        "### **Анализ производительности**\n",
        "\n",
        "1. **CPU с OpenMP**\n",
        "\n",
        "   * Время почти нулевое (0 мс) на данном массиве, потому что OpenMP эффективно распределяет работу по потокам CPU и массив относительно небольшой.\n",
        "   * Полная корректность, т.к. весь массив обрабатывается на CPU, нет проблем с памятью GPU.\n",
        "\n",
        "2. **GPU (CUDA)**\n",
        "\n",
        "   * Время выше, чем на CPU (7–8 мс), но это связано с накладными расходами на копирование данных между CPU и GPU и настройку блоков/потоков.\n",
        "   * Проверка корректности **ERROR**, значит есть ошибки в конфигурации ядра или копировании данных.\n",
        "   * GPU становится выгоден на **очень больших массивах**, когда накладные расходы распределяются на большое количество элементов.\n",
        "\n",
        "3. **Гибридная обработка (CPU + GPU)**\n",
        "\n",
        "   * Время около 8.874 мс, немного выше, чем чистый GPU, из-за накладных расходов на синхронизацию и разделение массива.\n",
        "   * Корректность **ERROR**, что указывает на ошибки при делении массива и объединении результатов.\n",
        "   * Гибридный подход **даёт наибольший выигрыш**, когда:\n",
        "\n",
        "     * Размер массива очень большой (миллионы элементов и выше).\n",
        "     * CPU и GPU могут одновременно обрабатывать данные без конфликтов.\n",
        "     * Правильно настроено разделение данных и синхронизация потоков.\n",
        "\n",
        "---\n",
        "\n",
        "### **Выводы**\n",
        "\n",
        "* Для **малых и средних массивов** CPU с OpenMP работает быстрее и безопаснее.\n",
        "* Для **очень больших массивов** GPU даёт выигрыш по времени, но требует корректной настройки памяти и конфигурации ядра.\n",
        "* **Гибридный режим** становится выгодным при массиве больших размеров, когда часть работы можно одновременно делегировать CPU, а часть GPU, при условии правильной синхронизации и копирования данных.\n"
      ],
      "metadata": {
        "id": "XBHoOPBskw7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Контрольные вопросы**\n",
        "\n",
        "**1. Какие преимущества предоставляют гибридные вычисления?**\n",
        "\n",
        "* Позволяют использовать сильные стороны **CPU и GPU одновременно**: CPU хорошо справляется с сложной логикой и ветвлениями, GPU — с массовым параллелизмом.\n",
        "* Увеличивают **общую производительность** при больших объёмах данных.\n",
        "* Снижают **время ожидания**, так как CPU и GPU могут работать одновременно над разными частями задачи.\n",
        "* Позволяют **распределять нагрузку**, чтобы оптимально использовать ресурсы компьютера.\n",
        "\n",
        "---\n",
        "\n",
        "**2. Как минимизировать накладные расходы при передаче данных между CPU и GPU?**\n",
        "\n",
        "* Использовать **выделение памяти GPU один раз** вместо частого `cudaMalloc` и `cudaFree`.\n",
        "* Копировать данные **блоками**, а не по элементам.\n",
        "* Применять **`cudaMemcpyAsync`** для асинхронного копирования с одновременной работой GPU.\n",
        "* Использовать **Unified Memory (`cudaMallocManaged`)**, чтобы исключить лишние копирования.\n",
        "* Минимизировать **частоту передачи данных** между CPU и GPU, передавая их один раз до и после основной обработки.\n",
        "\n",
        "---\n",
        "\n",
        "**3. Какие задачи лучше выполнять на CPU, а какие — на GPU?**\n",
        "\n",
        "* **CPU**:\n",
        "\n",
        "  * Задачи с ветвлениями, условными операторами, небольшими массивами.\n",
        "  * Сложная логика и последовательные вычисления.\n",
        "* **GPU**:\n",
        "\n",
        "  * Задачи с высокой степенью параллелизма.\n",
        "  * Массовая обработка массивов, матриц, графиков.\n",
        "  * Алгоритмы без сильной зависимости между элементами (например, векторные операции, параллельные умножения матриц).\n",
        "\n",
        "---\n",
        "\n",
        "**4. Как можно улучшить производительность гибридного приложения?**\n",
        "\n",
        "* Разделять массив **равномерно между CPU и GPU**, учитывая их мощность.\n",
        "* Минимизировать **синхронизацию потоков** и накладные расходы на копирование данных.\n",
        "* Использовать **оптимальные размеры блоков и сеток** для GPU.\n",
        "* Применять **асинхронные вычисления** и **параллельную обработку CPU и GPU**.\n",
        "* Профилировать программу с помощью инструментов (`nvprof`, Nsight, VTune), чтобы выявить узкие места.\n",
        "\n",
        "---\n",
        "\n",
        "### **Дополнительные задания (по желанию)**\n",
        "\n",
        "**1. Разные операции на CPU и GPU:**\n",
        "\n",
        "* Например, первая половина массива на CPU складывается с 1, а вторая половина на GPU умножается на 2.\n",
        "* Такой подход позволяет комбинировать разные алгоритмы и изучать гибридные вычисления.\n",
        "\n",
        "**2. Эксперименты с размерами массива:**\n",
        "\n",
        "* Малые массивы (менее миллиона элементов) — CPU может быть быстрее.\n",
        "* Средние массивы — GPU начинает выигрывать по времени.\n",
        "* Очень большие массивы (десятки миллионов элементов) — **гибридный режим** может быть наиболее эффективным, так как CPU и GPU работают одновременно.\n",
        "\n",
        "**3. Использование профилирования:**\n",
        "\n",
        "* `nvprof` или Nsight позволяют измерять:\n",
        "\n",
        "  * Время выполнения ядра GPU.\n",
        "  * Время передачи данных между CPU и GPU.\n",
        "  * Использование блоков и потоков GPU.\n",
        "* Это помогает оптимизировать размер блоков, количество потоков и уменьшить накладные расходы.\n",
        "\n"
      ],
      "metadata": {
        "id": "uP5qh0HclAnP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qBB4wlv9goc-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}