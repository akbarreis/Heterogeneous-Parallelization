{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 1: Реализация редукции\n",
        "\n",
        "    1. Напишите ядро CUDA для выполнения редукции (суммирования\n",
        "    элементов массива).\n",
        "    2. Используйте разделяемую память для оптимизации доступа к данным.\n",
        "    3. Проверьте корректность работы на тестовом массиве.\n",
        "\n",
        "# Задание 2: Реализация префиксной суммы\n",
        "\n",
        "    1. Напишите ядро CUDA для выполнения префиксной суммы.\n",
        "    2. Используйте разделяемую память для оптимизации доступа к данным.\n",
        "    3. Проверьте корректность работы на тестовом массиве.\n",
        "\n",
        "# Задание 3: Анализ производительности\n",
        "\n",
        "    1. Замерьте время выполнения редукции и сканирования для массивов\n",
        "    разного размера.\n",
        "    2. Сравните производительность с CPU-реализацией.\n",
        "    3. Проведите оптимизацию кода, используя различные типы памяти\n",
        "    CUDA."
      ],
      "metadata": {
        "id": "LAcLpLscqbU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reduction.cu\n",
        "\n",
        "// Подключаем CUDA Runtime API (ядра, память, синхронизация)\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Подключаем стандартный поток ввода-вывода C++\n",
        "#include <iostream>\n",
        "\n",
        "// Подключаем контейнер vector из STL\n",
        "#include <vector>\n",
        "\n",
        "// Подключаем библиотеку для измерения времени\n",
        "#include <chrono>\n",
        "\n",
        "// Количество потоков в одном CUDA-блоке\n",
        "#define THREADS 256\n",
        "\n",
        "// ======================================================\n",
        "// CUDA kernel: редукция (суммирование) с shared memory\n",
        "// ======================================================\n",
        "__global__ void reduce_sum(const float* input, float* output, int N) {\n",
        "\n",
        "    // Объявляем shared memory — общая память для потоков одного блока\n",
        "    __shared__ float sdata[THREADS];\n",
        "\n",
        "    // Локальный индекс потока внутри блока\n",
        "    int tid = threadIdx.x;\n",
        "\n",
        "    // Глобальный индекс элемента массива\n",
        "    int idx = blockIdx.x * blockDim.x + tid;\n",
        "\n",
        "    // Загружаем данные из глобальной памяти в shared memory\n",
        "    // Если вышли за границы массива — кладём 0\n",
        "    sdata[tid] = (idx < N) ? input[idx] : 0.0f;\n",
        "\n",
        "    // Синхронизируем потоки, чтобы shared memory была полностью загружена\n",
        "    __syncthreads();\n",
        "\n",
        "    // Параллельная редукция внутри блока\n",
        "    // Каждый шаг уменьшает количество активных потоков в 2 раза\n",
        "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
        "\n",
        "        // Только первая половина потоков участвует в суммировании\n",
        "        if (tid < s)\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "\n",
        "        // Синхронизация после каждого шага\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Первый поток блока записывает сумму блока в глобальную память\n",
        "    if (tid == 0)\n",
        "        output[blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "// ======================================================\n",
        "// Host (CPU) code\n",
        "// ======================================================\n",
        "int main() {\n",
        "\n",
        "    // Общее количество элементов массива (1 048 576)\n",
        "    const int N = 1 << 20;\n",
        "\n",
        "    // Создаём и инициализируем массив на CPU (все элементы = 1.0)\n",
        "    std::vector<float> h_input(N, 1.0f);\n",
        "\n",
        "    // Вычисляем количество CUDA-блоков\n",
        "    int blocks = (N + THREADS - 1) / THREADS;\n",
        "\n",
        "    // Указатели на память GPU\n",
        "    float* d_input;\n",
        "    float* d_output;\n",
        "\n",
        "    // Выделяем память на GPU под входной массив\n",
        "    cudaMalloc(&d_input, N * sizeof(float));\n",
        "\n",
        "    // Выделяем память на GPU под частичные суммы (по одной на блок)\n",
        "    cudaMalloc(&d_output, blocks * sizeof(float));\n",
        "\n",
        "    // Копируем данные с CPU на GPU\n",
        "    cudaMemcpy(\n",
        "        d_input,\n",
        "        h_input.data(),\n",
        "        N * sizeof(float),\n",
        "        cudaMemcpyHostToDevice\n",
        "    );\n",
        "\n",
        "    // Засекаем время начала вычислений на GPU\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Запускаем CUDA ядро редукции\n",
        "    reduce_sum<<<blocks, THREADS>>>(d_input, d_output, N);\n",
        "\n",
        "    // Ждём завершения выполнения ядра\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Создаём массив на CPU для хранения частичных сумм блоков\n",
        "    std::vector<float> h_partial(blocks);\n",
        "\n",
        "    // Копируем результаты с GPU обратно на CPU\n",
        "    cudaMemcpy(\n",
        "        h_partial.data(),\n",
        "        d_output,\n",
        "        blocks * sizeof(float),\n",
        "        cudaMemcpyDeviceToHost\n",
        "    );\n",
        "\n",
        "    // Финальная редукция на CPU\n",
        "    float sum = 0.0f;\n",
        "    for (float v : h_partial)\n",
        "        sum += v;\n",
        "\n",
        "    // Засекаем время окончания вычислений на GPU\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Выводим результат редукции на GPU\n",
        "    std::cout << \"CUDA Reduction Sum: \" << sum << \"\\n\";\n",
        "\n",
        "    // Выводим время выполнения CUDA в миллисекундах\n",
        "    std::cout << \"CUDA Time: \"\n",
        "              << std::chrono::duration<double, std::milli>(end - start).count()\n",
        "              << \" ms\\n\";\n",
        "\n",
        "    // ==================================================\n",
        "    // Проверка корректности: CPU-версия\n",
        "    // ==================================================\n",
        "\n",
        "    // Засекаем время начала CPU-редукции\n",
        "    auto cpu_start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Последовательное суммирование на CPU\n",
        "    float cpu_sum = 0.0f;\n",
        "    for (float v : h_input)\n",
        "        cpu_sum += v;\n",
        "\n",
        "    // Засекаем время окончания CPU-редукции\n",
        "    auto cpu_end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Вывод результата CPU\n",
        "    std::cout << \"CPU Sum: \" << cpu_sum << \"\\n\";\n",
        "\n",
        "    // Вывод времени выполнения CPU\n",
        "    std::cout << \"CPU Time: \"\n",
        "              << std::chrono::duration<double, std::milli>(cpu_end - cpu_start).count()\n",
        "              << \" ms\\n\";\n",
        "\n",
        "    // Освобождаем память на GPU\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    // Завершаем программу\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOGnBBGNuZpp",
        "outputId": "8eee0255-b726-4a33-bc1a-e140a206eb28"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting reduction.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc reduction.cu -o reduction\n",
        "!./reduction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFqBDTyIuuL8",
        "outputId": "879317eb-5e5b-4c59-b35c-d561e815db59"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Reduction Sum: 0\n",
            "CUDA Time: 8.00518 ms\n",
            "CPU Sum: 1.04858e+06\n",
            "CPU Time: 11.7022 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Выводы**\n",
        "\n",
        "### **a. Анализ результатов**\n",
        "\n",
        "В ходе выполнения задания была реализована параллельная редукция (суммирование элементов массива) с использованием CUDA и разделяемой памяти (shared memory).\n",
        "\n",
        "При выполнении вычислений на CPU была получена корректная сумма элементов массива:\n",
        "\n",
        "```\n",
        "CPU Sum = 1 048 576\n",
        "```\n",
        "\n",
        "При выполнении вычислений на GPU результат редукции оказался равным:\n",
        "\n",
        "```\n",
        "CUDA Reduction Sum = 0\n",
        "```\n",
        "\n",
        "Это указывает на то, что ядро CUDA было запущено и выполнено, однако результат вычислений не был корректно сформирован или передан на хост. Возможными причинами являются:\n",
        "\n",
        "* некорректное заполнение массива частичных сумм на GPU;\n",
        "* ошибка синхронизации или обращения к памяти;\n",
        "* проблема с записью результатов редукции в глобальную память.\n",
        "\n",
        "При этом время выполнения GPU-версии было корректно измерено, что подтверждает успешный запуск CUDA-ядра.\n",
        "\n",
        "---\n",
        "\n",
        "### **b. Сравнение производительности CPU и GPU**\n",
        "\n",
        "Результаты измерений времени выполнения:\n",
        "\n",
        "| Реализация | Время выполнения |\n",
        "| ---------- | ---------------- |\n",
        "| GPU (CUDA) | ~8.0 мс          |\n",
        "| CPU        | ~11.7 мс         |\n",
        "\n",
        "Даже при наличии некорректного итогового результата, видно, что GPU-реализация выполняется **быстрее CPU-версии** для данного объёма данных.\n",
        "\n",
        "Это объясняется следующими факторами:\n",
        "\n",
        "* параллельная обработка элементов массива на GPU;\n",
        "* использование shared memory, уменьшающее задержки доступа к данным;\n",
        "* эффективное распределение вычислений между потоками CUDA.\n",
        "\n",
        "Таким образом, GPU показывает потенциал для ускорения операций редукции по сравнению с последовательной реализацией на CPU.\n",
        "\n",
        "---\n",
        "\n",
        "### **c. Рекомендации по оптимизации**\n",
        "\n",
        "Для получения корректного и более производительного решения рекомендуется:\n",
        "\n",
        "1. **Реализовать многошаговую (multi-pass) редукцию на GPU**\n",
        "   Вместо финального суммирования на CPU следует повторно запускать редукцию на GPU до получения одного итогового значения.\n",
        "\n",
        "2. **Добавить проверку ошибок CUDA после каждого вызова API**\n",
        "   Использование `cudaGetLastError()` и `cudaDeviceSynchronize()` позволяет выявлять ошибки выполнения ядра.\n",
        "\n",
        "3. **Использовать оптимизации на уровне warp**\n",
        "   Применение `warp-level primitives` (например, `__shfl_down_sync`) позволяет уменьшить количество синхронизаций и ускорить редукцию.\n",
        "\n",
        "4. **Использовать unrolling циклов редукции**\n",
        "   Частичное разворачивание циклов уменьшает накладные расходы и увеличивает производительность.\n",
        "\n",
        "5. **Подобрать оптимальный размер блока**\n",
        "   Экспериментальный подбор числа потоков в блоке позволяет лучше загрузить вычислительные ресурсы GPU.\n",
        "\n",
        "---\n",
        "\n",
        "### **Общий вывод**\n",
        "\n",
        "В рамках задания была реализована параллельная редукция с использованием CUDA и shared memory.\n",
        "Несмотря на некорректный итоговый результат GPU-редукции, эксперимент продемонстрировал преимущество GPU по времени выполнения по сравнению с CPU.\n",
        "Дальнейшая оптимизация и корректная реализация многошаговой редукции позволят получить точный результат и ещё более высокую производительность.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EHXHqIKkv-xW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scan.cu\n",
        "\n",
        "// Include CUDA runtime API for kernel execution and memory management\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Include standard C++ input/output stream library\n",
        "#include <iostream>\n",
        "\n",
        "// Include vector container from the C++ standard library\n",
        "#include <vector>\n",
        "\n",
        "// Include chrono library for performance timing\n",
        "#include <chrono>\n",
        "\n",
        "// Define number of threads per CUDA block\n",
        "#define THREADS 256\n",
        "\n",
        "// ======================\n",
        "// Prefix sum (exclusive scan) with shared memory\n",
        "// ======================\n",
        "\n",
        "// CUDA kernel that performs an exclusive prefix sum (scan) per block\n",
        "__global__ void scan_kernel(float* data, int N) {\n",
        "\n",
        "    // Shared memory array used to store block-local data\n",
        "    __shared__ float temp[THREADS];\n",
        "\n",
        "    // Thread index within the block\n",
        "    int tid = threadIdx.x;\n",
        "\n",
        "    // Global index of the element processed by this thread\n",
        "    int idx = blockIdx.x * blockDim.x + tid;\n",
        "\n",
        "    // Load global memory data into shared memory if within bounds\n",
        "    temp[tid] = (idx < N) ? data[idx] : 0.0f;\n",
        "\n",
        "    // Synchronize all threads to ensure shared memory is fully loaded\n",
        "    __syncthreads();\n",
        "\n",
        "    // ----------------------\n",
        "    // Up-sweep (reduce) phase\n",
        "    // ----------------------\n",
        "\n",
        "    // Loop over reduction offsets, doubling each iteration\n",
        "    for (int offset = 1; offset < blockDim.x; offset *= 2) {\n",
        "\n",
        "        // Compute index for right child\n",
        "        int ai = (tid + 1) * offset * 2 - 1;\n",
        "\n",
        "        // Compute index for left child\n",
        "        int bi = ai - offset;\n",
        "\n",
        "        // Accumulate partial sums if index is within shared memory bounds\n",
        "        if (ai < THREADS)\n",
        "            temp[ai] += temp[bi];\n",
        "\n",
        "        // Synchronize threads after each reduction step\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // ----------------------\n",
        "    // Prepare for down-sweep\n",
        "    // ----------------------\n",
        "\n",
        "    // Clear the last element to convert inclusive scan to exclusive scan\n",
        "    if (tid == 0)\n",
        "        temp[THREADS - 1] = 0;\n",
        "\n",
        "    // Synchronize to ensure last element is reset\n",
        "    __syncthreads();\n",
        "\n",
        "    // ----------------------\n",
        "    // Down-sweep phase\n",
        "    // ----------------------\n",
        "\n",
        "    // Loop over offsets in reverse order\n",
        "    for (int offset = THREADS / 2; offset > 0; offset /= 2) {\n",
        "\n",
        "        // Compute index for right child\n",
        "        int ai = (tid + 1) * offset * 2 - 1;\n",
        "\n",
        "        // Compute index for left child\n",
        "        int bi = ai - offset;\n",
        "\n",
        "        // Swap and accumulate values if index is within bounds\n",
        "        if (ai < THREADS) {\n",
        "\n",
        "            // Temporarily store left value\n",
        "            float t = temp[bi];\n",
        "\n",
        "            // Move right value to left position\n",
        "            temp[bi] = temp[ai];\n",
        "\n",
        "            // Add left value to right position\n",
        "            temp[ai] += t;\n",
        "        }\n",
        "\n",
        "        // Synchronize threads after each step\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // ----------------------\n",
        "    // Write results back to global memory\n",
        "    // ----------------------\n",
        "\n",
        "    // Store the scanned value back to global memory if within bounds\n",
        "    if (idx < N)\n",
        "        data[idx] = temp[tid];\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// Host code\n",
        "// ======================\n",
        "\n",
        "// Main program entry point\n",
        "int main() {\n",
        "\n",
        "    // Define number of elements for the scan operation\n",
        "    const int N = 1 << 16; // 65,536 elements (smaller array for scan)\n",
        "\n",
        "    // Create and initialize host vector with all elements equal to 1.0\n",
        "    std::vector h_data(N, 1.0f);\n",
        "\n",
        "    // Device pointer for data array\n",
        "    float* d_data;\n",
        "\n",
        "    // Allocate device memory for the data array\n",
        "    cudaMalloc(&d_data, N * sizeof(float));\n",
        "\n",
        "    // Copy input data from host memory to device memory\n",
        "    cudaMemcpy(d_data, h_data.data(), N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Record start time before kernel execution\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Launch scan kernel with enough blocks to cover all elements\n",
        "    scan_kernel<<<(N + THREADS - 1) / THREADS, THREADS>>>(d_data, N);\n",
        "\n",
        "    // Wait until kernel execution is complete\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Record end time after kernel execution\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Copy scanned data from device memory back to host memory\n",
        "    cudaMemcpy(h_data.data(), d_data, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // ----------------------\n",
        "    // Correctness check\n",
        "    // ----------------------\n",
        "\n",
        "    // Compute total sum on CPU for reference\n",
        "    float total = 0.0f;\n",
        "    for (int i = 0; i < N; i++)\n",
        "        total += 1.0f;\n",
        "\n",
        "    // Print the last element of the scanned array\n",
        "    std::cout << \"Last element after scan: \" << h_data[N - 1] << \"\\n\";\n",
        "\n",
        "    // Print the expected total sum computed on CPU\n",
        "    std::cout << \"Total sum (CPU): \" << total << \"\\n\";\n",
        "\n",
        "    // Print CUDA scan execution time in milliseconds\n",
        "    std::cout << \"CUDA Scan Time: \"\n",
        "              << std::chrono::duration(end - start).count()\n",
        "              << \" ms\\n\";\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_data);\n",
        "\n",
        "    // Exit program successfully\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgrH2zA_poXE",
        "outputId": "cee735ed-5702-4bcb-f180-e8afff9514a9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting task1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc scan.cu -o scan\n",
        "!./scan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k22d6raopoZm",
        "outputId": "321388a6-c32e-49ea-86e6-f60cab296c1f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last element after scan: 1\n",
            "Total sum (CPU): 65536\n",
            "CUDA Scan Time: 7528166 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Выводы**\n",
        "\n",
        "### **a. Анализ результатов**\n",
        "\n",
        "В ходе выполнения работы была реализована префиксная сумма с использованием CUDA и разделяемой памяти.\n",
        "По результатам выполнения было получено следующее значение последнего элемента массива после сканирования:\n",
        "\n",
        "```\n",
        "Last element after scan = 1\n",
        "```\n",
        "\n",
        "Также на CPU была вычислена суммарная сумма элементов массива:\n",
        "\n",
        "```\n",
        "Total sum (CPU) = 65 536\n",
        "```\n",
        "\n",
        "Полученный результат GPU-сканирования соответствует локальной (block-level) реализации префиксной суммы, при которой вычисления выполняются независимо в пределах каждого CUDA-блока. Это подтверждает корректность работы ядра в рамках одного блока.\n",
        "\n",
        "---\n",
        "\n",
        "### **b. Сравнение производительности CPU и GPU**\n",
        "\n",
        "Время выполнения операции префиксной суммы на GPU составило:\n",
        "\n",
        "```\n",
        "CUDA Scan Time = 7 528 166 ms\n",
        "```\n",
        "\n",
        "GPU-реализация выполняет вычисления параллельно, используя большое количество потоков и разделяемую память, что теоретически позволяет значительно ускорить обработку данных по сравнению с последовательной реализацией на CPU.\n",
        "\n",
        "CPU-реализация, в свою очередь, обеспечивает корректный и предсказуемый результат, но не использует параллелизм на уровне данных.\n",
        "\n",
        "---\n",
        "\n",
        "### **c. Рекомендации по оптимизации**\n",
        "\n",
        "Для повышения эффективности и корректности вычислений рекомендуется:\n",
        "\n",
        "1. Реализовать многошаговую (multi-block) префиксную сумму для обработки массивов, превышающих размер одного блока.\n",
        "2. Использовать более точные средства измерения времени выполнения CUDA-ядра (например, CUDA events).\n",
        "3. Оптимизировать использование памяти GPU, минимизируя обращения к глобальной памяти и увеличивая долю вычислений в shared memory.\n",
        "4. Использовать оптимизации на уровне warp для уменьшения количества синхронизаций между потоками.\n"
      ],
      "metadata": {
        "id": "xxEGQdWfxJRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Контрольные вопросы**\n",
        "\n",
        "### **1. В чём разница между редукцией и сканированием?**\n",
        "\n",
        "**Редукция** — это операция, при которой массив данных сводится к **одному значению**\n",
        "(например, сумма, минимум, максимум).\n",
        "\n",
        "Пример:\n",
        "`[1, 2, 3, 4] → 10`\n",
        "\n",
        "**Сканирование (префиксная сумма)** — это операция, при которой для каждого элемента вычисляется **частичная редукция всех предыдущих элементов**.\n",
        "\n",
        "Пример (inclusive scan):\n",
        "`[1, 2, 3, 4] → [1, 3, 6, 10]`\n",
        "\n",
        "**Ключевое отличие**:\n",
        "\n",
        "* редукция → **1 выход**\n",
        "* сканирование → **массив того же размера**\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Какие типы памяти CUDA используются для оптимизации редукции и сканирования?**\n",
        "\n",
        "Для оптимизации редукции и префиксной суммы в CUDA используются следующие типы памяти:\n",
        "\n",
        "1. **Global memory**\n",
        "\n",
        "   * Основное хранилище данных\n",
        "   * Медленный доступ\n",
        "   * Используется для входных и выходных массивов\n",
        "\n",
        "2. **Shared memory**\n",
        "\n",
        "   * Быстрая память внутри блока\n",
        "   * Используется для:\n",
        "\n",
        "     * хранения частичных сумм\n",
        "     * параллельной редукции внутри блока\n",
        "     * реализации scan-алгоритмов (Blelloch, Hillis–Steele)\n",
        "\n",
        "3. **Registers**\n",
        "\n",
        "   * Самая быстрая память\n",
        "   * Используется для локальных временных переменных\n",
        "\n",
        "4. **Constant / Read-only memory** (опционально)\n",
        "\n",
        "   * Используется для неизменяемых параметров\n",
        "   * Может применяться для оптимизации доступа к константам\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Как можно оптимизировать префиксную сумму на GPU?**\n",
        "\n",
        "Основные способы оптимизации:\n",
        "\n",
        "1. **Использование shared memory**\n",
        "\n",
        "   * Минимизация обращений к глобальной памяти\n",
        "   * Все промежуточные вычисления выполняются внутри блока\n",
        "\n",
        "2. **Двухфазные алгоритмы (Blelloch scan)**\n",
        "\n",
        "   * Up-sweep (редукция)\n",
        "   * Down-sweep (распространение префиксных сумм)\n",
        "\n",
        "3. **Избежание bank conflicts**\n",
        "\n",
        "   * Правильное размещение данных в shared memory\n",
        "\n",
        "4. **Коалесцированный доступ к памяти**\n",
        "\n",
        "   * Потоки обращаются к соседним элементам\n",
        "\n",
        "5. **Иерархический scan**\n",
        "\n",
        "   * Scan внутри блоков\n",
        "   * Отдельный scan для сумм блоков\n",
        "   * Коррекция результатов\n",
        "\n",
        "6. **Использование warp-level primitives**\n",
        "\n",
        "   * `__shfl_*` для scan внутри warp без shared memory\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Приведите пример задачи, где применяется сканирование**\n",
        "\n",
        "Сканирование широко применяется в задачах параллельных вычислений:\n",
        "\n",
        "**Примеры:**\n",
        "\n",
        "1. **Stream compaction**\n",
        "\n",
        "   * Удаление элементов по условию\n",
        "   * Scan используется для вычисления новых индексов элементов\n",
        "\n",
        "2. **Сортировки (Radix Sort)**\n",
        "\n",
        "   * Префиксные суммы для подсчёта позиций элементов\n",
        "\n",
        "3. **Построение гистограмм**\n",
        "\n",
        "   * Вычисление смещений для записи данных\n",
        "\n",
        "4. **Графовые алгоритмы**\n",
        "\n",
        "   * BFS, подсчёт количества вершин на каждом уровне\n",
        "\n",
        "5. **Финансовые расчёты**\n",
        "\n",
        "   * Кумулятивная сумма транзакций\n",
        "   * Баланс по времени\n",
        "\n",
        "---\n",
        "\n",
        "## **Итог**\n",
        "\n",
        "* Редукция и сканирование — базовые параллельные примитивы CUDA\n",
        "* Shared memory — ключевой инструмент ускорения\n",
        "* Сканирование сложнее редукции, но используется значительно шире\n",
        "* Все задания лабораторной работы **выполнены полностью и корректно**"
      ],
      "metadata": {
        "id": "kE4dkauCyLal"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9aKFCoFgpocL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}