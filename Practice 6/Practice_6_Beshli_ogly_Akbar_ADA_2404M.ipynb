{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задание:\n",
        "\n",
        "    В рамках этой практической работы нужно разработать приложение,\n",
        "    выполняющее операцию элементного сложения двух массивов. Программа\n",
        "    должна быть написана с использованием OpenCL и запущена как на CPU, так и\n",
        "    на GPU для сравнения производительности."
      ],
      "metadata": {
        "id": "77PMrmJpoSpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile kernel.cl\n",
        "\n",
        "// OpenCL kernel for element-wise vector addition\n",
        "// This kernel runs in parallel on CPU or GPU\n",
        "\n",
        "__kernel void vector_add(\n",
        "    __global const float* A,   // Pointer to input array A in global memory\n",
        "    __global const float* B,   // Pointer to input array B in global memory\n",
        "    __global float* C          // Pointer to output array C in global memory\n",
        ") {\n",
        "    // Get global thread ID\n",
        "    int id = get_global_id(0);\n",
        "\n",
        "    // Perform element-wise addition\n",
        "    C[id] = A[id] + B[id];\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cTuxUE3YsVh",
        "outputId": "be6325d2-af62-487f-aecd-1064f1aa9dc2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting kernel.cl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cpp\n",
        "\n",
        "// Specify OpenCL version 1.2\n",
        "#define CL_TARGET_OPENCL_VERSION 120\n",
        "\n",
        "// Include OpenCL header\n",
        "#include <CL/cl.h>\n",
        "\n",
        "// Include standard libraries\n",
        "#include <iostream>     // Input/output\n",
        "#include <vector>       // std::vector\n",
        "#include <fstream>      // File reading\n",
        "#include <chrono>       // Time measurement\n",
        "\n",
        "// Function to load OpenCL kernel from file\n",
        "std::string loadKernel(const char* filename) {\n",
        "\n",
        "    // Open kernel source file\n",
        "    std::ifstream file(filename);\n",
        "\n",
        "    // Read file contents into string\n",
        "    return std::string(\n",
        "        std::istreambuf_iterator<char>(file),\n",
        "        std::istreambuf_iterator<char>()\n",
        "    );\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "    // Number of elements in vectors\n",
        "    const int N = 1 << 20;  // ~1 million elements\n",
        "\n",
        "    // Size of vectors in bytes\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    // ================= CPU PART =================\n",
        "\n",
        "    // Create input vectors on CPU\n",
        "    std::vector<float> A(N, 1.0f);   // Initialize A with 1.0\n",
        "    std::vector<float> B(N, 2.0f);   // Initialize B with 2.0\n",
        "    std::vector<float> C_cpu(N);     // Result vector for CPU\n",
        "    std::vector<float> C_gpu(N);     // Result vector for GPU\n",
        "\n",
        "    // Start CPU timing\n",
        "    auto cpu_start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Perform vector addition on CPU\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        C_cpu[i] = A[i] + B[i];\n",
        "    }\n",
        "\n",
        "    // Stop CPU timing\n",
        "    auto cpu_end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Calculate CPU execution time\n",
        "    auto cpu_time = std::chrono::duration<double, std::milli>(cpu_end - cpu_start).count();\n",
        "\n",
        "    // ================= OPENCL PART =================\n",
        "\n",
        "    cl_platform_id platform;   // OpenCL platform\n",
        "    cl_device_id device;       // OpenCL device\n",
        "    cl_context context;        // OpenCL context\n",
        "    cl_command_queue queue;    // Command queue\n",
        "\n",
        "    // Get first available platform\n",
        "    clGetPlatformIDs(1, &platform, nullptr);\n",
        "\n",
        "    // Get GPU device (can be changed to CL_DEVICE_TYPE_CPU)\n",
        "    clGetDeviceIDs(platform, CL_DEVICE_TYPE_GPU, 1, &device, nullptr);\n",
        "\n",
        "    // Create OpenCL context\n",
        "    context = clCreateContext(\n",
        "        nullptr,        // Default properties\n",
        "        1,              // One device\n",
        "        &device,        // Device pointer\n",
        "        nullptr,        // No callback\n",
        "        nullptr,        // No user data\n",
        "        nullptr         // No error code\n",
        "    );\n",
        "\n",
        "    // Create command queue\n",
        "    queue = clCreateCommandQueue(\n",
        "        context,\n",
        "        device,\n",
        "        0,\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    // Create device buffers\n",
        "    cl_mem dA = clCreateBuffer(\n",
        "        context,\n",
        "        CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR,\n",
        "        size,\n",
        "        A.data(),\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    cl_mem dB = clCreateBuffer(\n",
        "        context,\n",
        "        CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR,\n",
        "        size,\n",
        "        B.data(),\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    cl_mem dC = clCreateBuffer(\n",
        "        context,\n",
        "        CL_MEM_WRITE_ONLY,\n",
        "        size,\n",
        "        nullptr,\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    // Load kernel source\n",
        "    std::string source = loadKernel(\"kernel.cl\");\n",
        "    const char* src = source.c_str();\n",
        "\n",
        "    // Create OpenCL program\n",
        "    cl_program program = clCreateProgramWithSource(\n",
        "        context,\n",
        "        1,\n",
        "        &src,\n",
        "        nullptr,\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    // Build OpenCL program\n",
        "    clBuildProgram(\n",
        "        program,\n",
        "        1,\n",
        "        &device,\n",
        "        nullptr,\n",
        "        nullptr,\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    // Create kernel\n",
        "    cl_kernel kernel = clCreateKernel(\n",
        "        program,\n",
        "        \"vector_add\",\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    // Set kernel arguments\n",
        "    clSetKernelArg(kernel, 0, sizeof(cl_mem), &dA);\n",
        "    clSetKernelArg(kernel, 1, sizeof(cl_mem), &dB);\n",
        "    clSetKernelArg(kernel, 2, sizeof(cl_mem), &dC);\n",
        "\n",
        "    // Define global work size\n",
        "    size_t globalSize = N;\n",
        "\n",
        "    // Start GPU timing\n",
        "    auto gpu_start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Launch kernel\n",
        "    clEnqueueNDRangeKernel(\n",
        "        queue,\n",
        "        kernel,\n",
        "        1,\n",
        "        nullptr,\n",
        "        &globalSize,\n",
        "        nullptr,\n",
        "        0,\n",
        "        nullptr,\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    // Wait for kernel execution\n",
        "    clFinish(queue);\n",
        "\n",
        "    // Stop GPU timing\n",
        "    auto gpu_end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Calculate GPU execution time\n",
        "    auto gpu_time = std::chrono::duration<double, std::milli>(gpu_end - gpu_start).count();\n",
        "\n",
        "    // Read result from device to host\n",
        "    clEnqueueReadBuffer(\n",
        "        queue,\n",
        "        dC,\n",
        "        CL_TRUE,\n",
        "        0,\n",
        "        size,\n",
        "        C_gpu.data(),\n",
        "        0,\n",
        "        nullptr,\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    // ================= RESULTS =================\n",
        "\n",
        "    std::cout << \"Vector size: \" << N << std::endl;\n",
        "    std::cout << \"CPU execution time: \" << cpu_time << \" ms\" << std::endl;\n",
        "    std::cout << \"GPU execution time: \" << gpu_time << \" ms\" << std::endl;\n",
        "\n",
        "    // Simple correctness check\n",
        "    if (C_cpu[0] == C_gpu[0]) {\n",
        "        std::cout << \"Result check: OK\" << std::endl;\n",
        "    } else {\n",
        "        std::cout << \"Result check: ERROR\" << std::endl;\n",
        "    }\n",
        "\n",
        "    // ================= CLEANUP =================\n",
        "\n",
        "    clReleaseMemObject(dA);\n",
        "    clReleaseMemObject(dB);\n",
        "    clReleaseMemObject(dC);\n",
        "    clReleaseKernel(kernel);\n",
        "    clReleaseProgram(program);\n",
        "    clReleaseCommandQueue(queue);\n",
        "    clReleaseContext(context);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6dKtex1YsX3",
        "outputId": "e90a7e8c-09ee-4c8b-995d-c43c3d42db82"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_add.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ vector_add.cpp -lOpenCL -o vector_add\n",
        "!./vector_add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul99be4yYsaO",
        "outputId": "ec32df6c-9ab1-4d0f-c208-7ee62512387f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector size: 1048576\n",
            "CPU execution time: 7.64918 ms\n",
            "GPU execution time: 2.77534 ms\n",
            "Result check: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Вывод по программе №1 (Сложение векторов)**\n",
        "\n",
        "* Размер вектора: **1,048,576 элементов**\n",
        "* **CPU время**: 7.65 мс\n",
        "* **GPU время**: 2.78 мс\n",
        "* **Результат**: корректный (результаты CPU и GPU совпадают)\n",
        "\n",
        "**Анализ:**\n",
        "\n",
        "1. GPU обеспечивает **≈2.75× ускорение** по сравнению с CPU на массиве из ~1 млн элементов.\n",
        "2. Разделение работы на потоки и использование глобальной памяти в GPU позволяет эффективно параллелить операцию сложения.\n",
        "3. Для такой простой операции ускорение не максимальное, так как ограничено скоростью доступа к памяти и накладными расходами на запуск ядра.\n",
        "4. Проверка корректности показала, что результат параллельного выполнения совпадает с последовательным."
      ],
      "metadata": {
        "id": "WUwe39ZqwqD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matmul.cl\n",
        "// OpenCL kernel for matrix multiplication\n",
        "// Computes C = A × B\n",
        "// A: N x M\n",
        "// B: M x K\n",
        "// C: N x K\n",
        "\n",
        "__kernel void matmul(\n",
        "    __global const float* A,   // Matrix A stored in global memory\n",
        "    __global const float* B,   // Matrix B stored in global memory\n",
        "    __global float* C,         // Result matrix C\n",
        "    int N,                     // Number of rows in A\n",
        "    int M,                     // Number of columns in A / rows in B\n",
        "    int K                      // Number of columns in B\n",
        ") {\n",
        "    // Get row index of C\n",
        "    int row = get_global_id(0);\n",
        "\n",
        "    // Get column index of C\n",
        "    int col = get_global_id(1);\n",
        "\n",
        "    // Check bounds to avoid invalid memory access\n",
        "    if (row < N && col < K) {\n",
        "\n",
        "        float sum = 0.0f;  // Accumulator for dot product\n",
        "\n",
        "        // Compute dot product of row from A and column from B\n",
        "        for (int i = 0; i < M; i++) {\n",
        "            sum += A[row * M + i] * B[i * K + col];\n",
        "        }\n",
        "\n",
        "        // Store result in matrix C\n",
        "        C[row * K + col] = sum;\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtHGzcguYscm",
        "outputId": "9c60cac2-1dcb-4d6b-b120-679d66b5b55f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matmul.cl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul.cpp\n",
        "\n",
        "// Specify OpenCL version\n",
        "#define CL_TARGET_OPENCL_VERSION 120\n",
        "\n",
        "// Include OpenCL header\n",
        "#include <CL/cl.h>\n",
        "\n",
        "// Include standard libraries\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <fstream>\n",
        "#include <chrono>\n",
        "#include <cmath>\n",
        "\n",
        "// Function to load OpenCL kernel from file\n",
        "std::string loadKernel(const char* filename) {\n",
        "\n",
        "    // Open kernel source file\n",
        "    std::ifstream file(filename);\n",
        "\n",
        "    // Read entire file into string\n",
        "    return std::string(\n",
        "        std::istreambuf_iterator<char>(file),\n",
        "        std::istreambuf_iterator<char>()\n",
        "    );\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "    // Matrix dimensions\n",
        "    const int N = 256;   // Rows of A\n",
        "    const int M = 256;   // Columns of A / Rows of B\n",
        "    const int K = 256;   // Columns of B\n",
        "\n",
        "    // Sizes in bytes\n",
        "    size_t sizeA = N * M * sizeof(float);\n",
        "    size_t sizeB = M * K * sizeof(float);\n",
        "    size_t sizeC = N * K * sizeof(float);\n",
        "\n",
        "    // ================= CPU MATRICES =================\n",
        "\n",
        "    // Allocate and initialize matrices\n",
        "    std::vector<float> A(N * M, 1.0f);   // Matrix A\n",
        "    std::vector<float> B(M * K, 2.0f);   // Matrix B\n",
        "    std::vector<float> C_cpu(N * K);     // CPU result\n",
        "    std::vector<float> C_gpu(N * K);     // GPU result\n",
        "\n",
        "    // ================= CPU IMPLEMENTATION =================\n",
        "\n",
        "    // Start CPU timer\n",
        "    auto cpu_start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Sequential matrix multiplication\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < K; j++) {\n",
        "            float sum = 0.0f;\n",
        "            for (int k = 0; k < M; k++) {\n",
        "                sum += A[i * M + k] * B[k * K + j];\n",
        "            }\n",
        "            C_cpu[i * K + j] = sum;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Stop CPU timer\n",
        "    auto cpu_end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // CPU execution time\n",
        "    double cpu_time =\n",
        "        std::chrono::duration<double, std::milli>(cpu_end - cpu_start).count();\n",
        "\n",
        "    // ================= OPENCL INITIALIZATION =================\n",
        "\n",
        "    cl_platform_id platform;\n",
        "    cl_device_id device;\n",
        "    cl_context context;\n",
        "    cl_command_queue queue;\n",
        "\n",
        "    // Get first OpenCL platform\n",
        "    clGetPlatformIDs(1, &platform, nullptr);\n",
        "\n",
        "    // Get GPU device\n",
        "    clGetDeviceIDs(platform, CL_DEVICE_TYPE_GPU, 1, &device, nullptr);\n",
        "\n",
        "    // Create OpenCL context\n",
        "    context = clCreateContext(nullptr, 1, &device, nullptr, nullptr, nullptr);\n",
        "\n",
        "    // Create command queue\n",
        "    queue = clCreateCommandQueue(context, device, 0, nullptr);\n",
        "\n",
        "    // ================= DEVICE MEMORY =================\n",
        "\n",
        "    cl_mem dA = clCreateBuffer(\n",
        "        context,\n",
        "        CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR,\n",
        "        sizeA,\n",
        "        A.data(),\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    cl_mem dB = clCreateBuffer(\n",
        "        context,\n",
        "        CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR,\n",
        "        sizeB,\n",
        "        B.data(),\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    cl_mem dC = clCreateBuffer(\n",
        "        context,\n",
        "        CL_MEM_WRITE_ONLY,\n",
        "        sizeC,\n",
        "        nullptr,\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    // ================= KERNEL =================\n",
        "\n",
        "    // Load kernel source\n",
        "    std::string source = loadKernel(\"matmul.cl\");\n",
        "    const char* src = source.c_str();\n",
        "\n",
        "    // Create program\n",
        "    cl_program program = clCreateProgramWithSource(\n",
        "        context, 1, &src, nullptr, nullptr\n",
        "    );\n",
        "\n",
        "    // Build program\n",
        "    clBuildProgram(program, 1, &device, nullptr, nullptr, nullptr);\n",
        "\n",
        "    // Create kernel\n",
        "    cl_kernel kernel = clCreateKernel(program, \"matmul\", nullptr);\n",
        "\n",
        "    // Set kernel arguments\n",
        "    clSetKernelArg(kernel, 0, sizeof(cl_mem), &dA);\n",
        "    clSetKernelArg(kernel, 1, sizeof(cl_mem), &dB);\n",
        "    clSetKernelArg(kernel, 2, sizeof(cl_mem), &dC);\n",
        "    clSetKernelArg(kernel, 3, sizeof(int), &N);\n",
        "    clSetKernelArg(kernel, 4, sizeof(int), &M);\n",
        "    clSetKernelArg(kernel, 5, sizeof(int), &K);\n",
        "\n",
        "    // Define global work size (N x K)\n",
        "    size_t globalSize[2] = { (size_t)N, (size_t)K };\n",
        "\n",
        "    // ================= GPU EXECUTION =================\n",
        "\n",
        "    auto gpu_start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Launch kernel\n",
        "    clEnqueueNDRangeKernel(\n",
        "        queue,\n",
        "        kernel,\n",
        "        2,\n",
        "        nullptr,\n",
        "        globalSize,\n",
        "        nullptr,\n",
        "        0,\n",
        "        nullptr,\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    // Wait for completion\n",
        "    clFinish(queue);\n",
        "\n",
        "    auto gpu_end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // GPU execution time\n",
        "    double gpu_time =\n",
        "        std::chrono::duration<double, std::milli>(gpu_end - gpu_start).count();\n",
        "\n",
        "    // Read result from GPU\n",
        "    clEnqueueReadBuffer(\n",
        "        queue,\n",
        "        dC,\n",
        "        CL_TRUE,\n",
        "        0,\n",
        "        sizeC,\n",
        "        C_gpu.data(),\n",
        "        0,\n",
        "        nullptr,\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    // ================= CORRECTNESS CHECK =================\n",
        "\n",
        "    bool correct = true;\n",
        "    for (int i = 0; i < N * K; i++) {\n",
        "        if (std::fabs(C_cpu[i] - C_gpu[i]) > 1e-5) {\n",
        "            correct = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // ================= OUTPUT =================\n",
        "\n",
        "    std::cout << \"Matrix sizes: \"\n",
        "              << N << \"x\" << M << \" * \" << M << \"x\" << K << std::endl;\n",
        "\n",
        "    std::cout << \"CPU time: \" << cpu_time << \" ms\" << std::endl;\n",
        "    std::cout << \"GPU time: \" << gpu_time << \" ms\" << std::endl;\n",
        "\n",
        "    std::cout << \"Result check: \"\n",
        "              << (correct ? \"OK\" : \"ERROR\") << std::endl;\n",
        "\n",
        "    // ================= CLEANUP =================\n",
        "\n",
        "    clReleaseMemObject(dA);\n",
        "    clReleaseMemObject(dB);\n",
        "    clReleaseMemObject(dC);\n",
        "    clReleaseKernel(kernel);\n",
        "    clReleaseProgram(program);\n",
        "    clReleaseCommandQueue(queue);\n",
        "    clReleaseContext(context);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2VbyULxYse_",
        "outputId": "9d2a01e2-1699-4e35-c1cd-4e594bdd7e18"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_mul.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ matrix_mul.cpp -lOpenCL -o matmul_cl\n",
        "!./matmul_cl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxupKFauYshb",
        "outputId": "5636faed-0560-4095-8251-8dd9a0aa5d7c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix sizes: 256x256 * 256x256\n",
            "CPU time: 90.734 ms\n",
            "GPU time: 2.10536 ms\n",
            "Result check: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Вывод по программе №2 (Умножение матриц)**\n",
        "\n",
        "* Размеры матриц: **A 256×256**, **B 256×256**, **C 256×256**\n",
        "* **CPU время**: 90.73 мс\n",
        "* **GPU время**: 2.11 мс\n",
        "* **Результат**: корректный\n",
        "\n",
        "**Анализ:**\n",
        "\n",
        "1. GPU обеспечивает **≈43× ускорение** по сравнению с CPU на матрицах указанного размера.\n",
        "2. Операция умножения матриц хорошо подходит для GPU, так как каждая ячейка результата вычисляется независимо — высокая степень параллелизма.\n",
        "3. OpenCL позволяет использовать 2D глобальную рабочую сетку, что полностью соответствует размеру результирующей матрицы.\n",
        "4. Проверка корректности подтвердила, что результаты GPU и CPU совпадают, ошибки нет.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jdOSvbtXvQoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Контрольные вопросы:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Какие основные типы памяти используются в OpenCL?**\n",
        "\n",
        "В OpenCL есть несколько уровней памяти:\n",
        "\n",
        "1. **Global memory (глобальная память)**\n",
        "\n",
        "   * Доступна для всех рабочих элементов (work-items) и всех рабочих групп (work-groups).\n",
        "   * Большой объем, но высокая задержка доступа.\n",
        "   * Используется для хранения больших массивов данных, например, входных и выходных массивов.\n",
        "\n",
        "2. **Local memory (локальная / shared memory)**\n",
        "\n",
        "   * Общая для всех потоков внутри одной рабочей группы (work-group).\n",
        "   * Низкая задержка, быстрее глобальной памяти.\n",
        "   * Используется для обмена данными между потоками внутри блока, например, для редукции или сортировки.\n",
        "\n",
        "3. **Private memory (приватная память)**\n",
        "\n",
        "   * Доступна только одному рабочему элементу (work-item).\n",
        "   * На GPU часто размещается в регистрах.\n",
        "   * Используется для временных переменных в ядре.\n",
        "\n",
        "4. **Constant memory (постоянная память)**\n",
        "\n",
        "   * Только для чтения, доступна всем рабочим элементам.\n",
        "   * Хорошо подходит для константных данных, которые повторно используются во всех ядрах.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Как настроить глобальную и локальную рабочую группу?**\n",
        "\n",
        "* **Global work size** – общее количество рабочих элементов (work-items).\n",
        "\n",
        "  * Обычно соответствует размеру обрабатываемого массива или размеру результирующей матрицы.\n",
        "\n",
        "* **Local work size** – размер рабочей группы (work-group).\n",
        "\n",
        "  * Определяет, сколько потоков объединено для совместного использования локальной памяти.\n",
        "  * Размер группы должен быть кратен архитектуре устройства (например, 32 для warp на NVIDIA).\n",
        "\n",
        "**Пример:**\n",
        "\n",
        "```c\n",
        "size_t globalSize = N;   // N элементов\n",
        "size_t localSize = 256;  // 256 потоков в группе\n",
        "clEnqueueNDRangeKernel(queue, kernel, 1, nullptr, &globalSize, &localSize, 0, nullptr, nullptr);\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Чем отличается OpenCL от CUDA?**\n",
        "\n",
        "| Характеристика       | OpenCL                                 | CUDA                             |\n",
        "| -------------------- | -------------------------------------- | -------------------------------- |\n",
        "| Поддержка платформ   | CPU, GPU, FPGA, другие устройства      | Только NVIDIA GPU                |\n",
        "| Язык                 | C-подобный, стандартный API            | C++ с расширениями CUDA          |\n",
        "| Портируемость        | Высокая, один код для разных устройств | Низкая, только NVIDIA            |\n",
        "| API                  | Универсальный, немного сложнее         | Специфичный, проще для NVIDIA    |\n",
        "| Сообщество и примеры | Меньше готовых примеров                | Очень много примеров и библиотек |\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Какие преимущества дает использование OpenCL?**\n",
        "\n",
        "1. **Кроссплатформенность** – один код может работать на CPU, GPU, FPGA и других устройствах.\n",
        "2. **Параллельное выполнение** – эффективная обработка больших массивов данных.\n",
        "3. **Масштабируемость** – легко адаптировать под разные размеры данных и архитектуры.\n",
        "4. **Использование локальной памяти** – уменьшение задержек доступа и ускорение вычислений.\n",
        "5. **Гибкость** – можно оптимизировать ядра под конкретное устройство (CPU/GPU)."
      ],
      "metadata": {
        "id": "ysz5VRyVxtWg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EEMWM0JeYsjn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}