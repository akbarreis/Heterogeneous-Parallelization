# Asignment 1: Динамическая память и параллельное программирование (C++ / OpenMP)

## Цель работы
Целью данной работы является изучение работы с динамической памятью
в языке C++, а также освоение базовых принципов параллельного программирования с использованием технологии OpenMP.

В ходе работы рассматриваются:
- динамическое выделение и освобождение памяти;
- работа с массивами и структурами данных;
- последовательные и параллельные алгоритмы;
- измерение времени выполнения программ.

---

## Используемые технологии
- Язык программирования: **C++**
- Параллельное программирование: **OpenMP**
- Компилятор: **GCC (g++ с поддержкой OpenMP)**
- Среда запуска: **Jupyter Notebook**

---

## Задание 1. Работа с динамическим массивом

В первом задании реализована программа, которая:
- динамически выделяет массив из 50 000 целых чисел;
- заполняет массив случайными значениями в заданном диапазоне;
- вычисляет среднее значение элементов массива;
- корректно освобождает выделенную память.

---

## Задание 2. Последовательный поиск минимума и максимума

Во втором задании:
- создаётся массив из 1 000 000 целых чисел;
- реализуется последовательный алгоритм поиска минимального и максимального элементов;
- измеряется время выполнения алгоритма с использованием библиотеки `<chrono>`.

Данное задание демонстрирует базовую сложность алгоритмов обработки массивов
и служит основой для последующего сравнения с параллельной реализацией.

---

## Задание 3. Параллельный поиск минимума и максимума (OpenMP)

В третьем задании:
- используется массив из задания 2;
- реализуется параллельный поиск минимума и максимума с помощью OpenMP;
- применяется директива `reduction` для корректного объединения результатов;
- проводится сравнение времени выполнения последовательной и параллельной версий.

Результаты показывают, что при работе с большими массивами параллельная версия
может значительно ускорить вычисления за счёт использования нескольких потоков CPU.

---

## Задание 4. Последовательное и параллельное вычисление среднего значения

В четвёртом задании:
- создаётся массив из 5 000 000 элементов;
- вычисляется среднее значение элементов массива последовательным способом;
- выполняется параллельный подсчёт суммы с использованием OpenMP и редукции;
- сравнивается время выполнения обеих реализаций.

Данное задание наглядно демонстрирует влияние параллельного программирования
на производительность при обработке больших объёмов данных.

---

## Выводы

В ходе выполнения работы были получены следующие результаты:
- освоены принципы работы с динамической памятью в C++;
- изучены базовые структуры данных и алгоритмы их обработки;
- получены практические навыки использования OpenMP;
- установлено, что параллельное программирование позволяет существенно
  сократить время выполнения вычислений для больших массивов данных,
  однако при малом объёме данных накладные расходы могут превышать выигрыш.

---

## Запуск программ

Для компиляции и запуска программ с поддержкой OpenMP используется следующая команда:

```bash
g++ -fopenmp имя_файла.cpp -o имя_программы
./имя_программы
```

## Контрольные вопросы

### 1. В чём отличие динамического массива от статического массива в языке C++?

Статический массив имеет фиксированный размер, определяемый во время компиляции, и обычно размещается в стеке.  
Динамический массив выделяется во время выполнения программы, его размер может задаваться динамически, а память размещается в куче.

---

### 2. Что такое указатель и зачем он используется при работе с динамической памятью?

Указатель — это переменная, хранящая адрес области памяти.  
При работе с динамической памятью указатели используются для доступа к памяти, выделенной в куче, так как такие объекты не имеют собственного имени.

---

### 3. Почему важно корректно освобождать память после использования динамических массивов?

Некорректное освобождение памяти приводит к утечкам памяти, которые увеличивают потребление ресурсов и могут снизить производительность программы или привести к её аварийному завершению.

---

### 4. В чём разница между последовательной и параллельной обработкой массива?

При последовательной обработке массив обрабатывается одним потоком поочерёдно.  
При параллельной обработке работа распределяется между несколькими потоками, которые выполняются одновременно на разных ядрах процессора.

---

### 5. Что делает директива `#pragma omp parallel for`?

Директива `#pragma omp parallel for` распараллеливает цикл `for`, распределяя его итерации между несколькими потоками для одновременного выполнения.

---

### 6. Для чего используется механизм `reduction` в OpenMP?

Механизм `reduction` используется для корректного объединения частичных результатов, вычисленных разными потоками, в одно итоговое значение.

---

### 7. Почему при параллельном вычислении суммы необходимо использовать `reduction`, а не обычную переменную?

Без использования `reduction` возникает состояние гонки, так как несколько потоков одновременно изменяют одну переменную.  
`reduction` создаёт локальные копии переменной для каждого потока и корректно объединяет результаты.

---

### 8. Какие факторы могут привести к тому, что параллельная версия программы будет работать медленнее последовательной?

Параллельная версия может работать медленнее из-за накладных расходов на создание потоков, синхронизацию, малого объёма данных, неравномерного распределения нагрузки и ограниченного числа вычислительных ядер.

---
