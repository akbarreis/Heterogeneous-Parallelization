# Final Project

## Параллельное построение гистограммы на CPU и GPU

---

## 1. Теоретический материал

### 1.1. Гистограмма и постановка задачи

**Гистограмма** — это структура данных, показывающая частоту появления значений в массиве данных.
В данной работе рассматривается построение гистограммы с **256 бинами** для массива байтов (`unsigned char`), значения которых лежат в диапазоне `[0, 255]`.

Задача состоит в том, чтобы:

* реализовать построение гистограммы **последовательно на CPU**;
* реализовать **параллельную версию на CPU с использованием OpenMP**;
* реализовать **параллельные версии на GPU (CUDA)**:

  * с использованием `atomic` операций в глобальной памяти;
  * с использованием **shared memory** и последующей редукции;
* сравнить время выполнения и корректность результатов;
* проанализировать влияние конкуренции за атомарные операции.

---

### 1.2. Последовательное вычисление на CPU

В последовательной версии:

* используется один поток;
* каждый элемент массива обрабатывается по очереди;
* соответствующий бин гистограммы увеличивается на 1.

Преимущества:

* простота реализации;
* отсутствие проблем синхронизации.

Недостатки:

* низкая производительность при больших объёмах данных;
* отсутствие масштабируемости.

---

### 1.3. Параллелизм на CPU с использованием OpenMP

**OpenMP** позволяет распараллелить вычисления на уровне потоков CPU.

В данной реализации:

* каждый поток использует **локальную гистограмму** (`local_hist`);
* данные распределяются между потоками с помощью директивы `#pragma omp for`;
* после завершения вычислений локальные гистограммы объединяются в общую с использованием критической секции.

Преимущества:

* значительное ускорение по сравнению с последовательной версией;
* простота добавления параллелизма.

Недостатки:

* использование `critical` секции может стать узким местом;
* масштабируемость ограничена количеством ядер CPU.

---

### 1.4. Параллелизм на GPU (CUDA)

GPU обеспечивает массовый параллелизм за счёт тысяч потоков, организованных в блоки.

#### 1.4.1. CUDA atomic версия

В atomic-версии:

* каждый поток обрабатывает один элемент массива;
* обновление глобальной гистограммы выполняется через `atomicAdd`.

Преимущества:

* простая реализация;
* корректность за счёт атомарных операций.

Недостатки:

* высокая конкуренция за доступ к глобальной памяти;
* значительное снижение производительности при большом числе потоков.

---

#### 1.4.2. CUDA shared memory версия

В shared memory версии:

* каждый блок использует локальную гистограмму в **shared memory**;
* потоки внутри блока обновляют shared-гистограмму;
* после завершения подсчёта выполняется редукция в глобальную память.

Преимущества:

* снижение количества атомарных операций в глобальной памяти;
* более высокая производительность по сравнению с atomic-версией.

Недостатки:

* ограничение по размеру shared memory;
* усложнение реализации;
* необходимость синхронизации потоков внутри блока.

---

### 1.5. Проверка корректности

Корректность вычислений проверяется следующим условием:

> **Сумма всех бинов гистограммы должна быть равна числу элементов массива (N)**

Для данного проекта:

```
N = 10 000 000
```

Это условие используется для всех реализаций (CPU и GPU).

---

## 2. Контрольные вопросы

1. Что такое гистограмма и где она применяется?
2. Почему последовательная реализация гистограммы плохо масштабируется?
3. В чём заключается идея параллелизации гистограммы?
4. Какие проблемы возникают при параллельном обновлении общей памяти?
5. Как OpenMP позволяет распараллеливать вычисления на CPU?
6. Зачем в OpenMP используется локальная гистограмма для каждого потока?
7. Что такое атомарные операции в CUDA?
8. Почему использование `atomicAdd` в глобальной памяти может приводить к деградации производительности?
9. Что такое shared memory в CUDA и чем она отличается от глобальной памяти?
10. Зачем используется `__syncthreads()`?
11. В чём преимущество shared memory версии по сравнению с atomic версией?
12. Какие ограничения накладывает использование shared memory?
13. Почему важно обнулять память на GPU перед запуском ядра?
14. Как проверяется корректность работы параллельной гистограммы?
15. В каких случаях GPU-реализация будет значительно быстрее CPU?

---

## 3. Ответы на контрольные вопросы

---

### 1. Что такое гистограмма и где она применяется?

Гистограмма — это структура данных, которая показывает количество вхождений каждого значения в наборе данных.
Она широко применяется в обработке изображений, анализе сигналов, статистике, машинном обучении и задачах анализа больших данных.

---

### 2. Почему последовательная реализация гистограммы плохо масштабируется?

Последовательная реализация использует только один поток CPU, поэтому:

* не задействует многоядерную архитектуру;
* время выполнения линейно растёт с увеличением объёма данных;
* производительность ограничена возможностями одного ядра.

---

### 3. В чём заключается идея параллелизации гистограммы?

Идея параллелизации состоит в том, чтобы:

* распределить обработку элементов массива между несколькими потоками;
* позволить каждому потоку считать частоты для своей части данных;
* затем корректно объединить частичные результаты.

---

### 4. Какие проблемы возникают при параллельном обновлении общей памяти?

Основные проблемы:

* **состояния гонки (race conditions)**;
* потеря данных при одновременной записи;
* необходимость синхронизации, которая снижает производительность.

---

### 5. Как OpenMP позволяет распараллеливать вычисления на CPU?

OpenMP использует директивы компилятора (`#pragma omp`), которые:

* автоматически создают пул потоков;
* распределяют итерации циклов между потоками;
* управляют синхронизацией и разделяемой памятью.

---

### 6. Зачем в OpenMP используется локальная гистограмма для каждого потока?

Локальная гистограмма:

* исключает состояния гонки при обновлении бинов;
* уменьшает количество операций синхронизации;
* повышает производительность по сравнению с прямым доступом к общей памяти.

---

### 7. Что такое атомарные операции в CUDA?

Атомарные операции — это операции, которые выполняются **неделимо**, гарантируя корректность при одновременном доступе нескольких потоков к одному участку памяти.

Пример:

```cpp
atomicAdd(&hist[i], 1);
```

---

### 8. Почему использование `atomicAdd` в глобальной памяти может приводить к деградации производительности?

Потому что:

* множество потоков одновременно обращаются к одним и тем же бинам;
* происходит высокая конкуренция;
* доступ к глобальной памяти имеет большую задержку.

---

### 9. Что такое shared memory в CUDA и чем она отличается от глобальной памяти?

Shared memory:

* расположена внутри блока потоков;
* имеет значительно меньшую задержку;
* доступна только потокам одного блока.

Глобальная память:

* доступна всем потокам;
* имеет высокую задержку;
* используется для хранения итоговых результатов.

---

### 10. Зачем используется `__syncthreads()`?

`__syncthreads()`:

* синхронизирует все потоки внутри блока;
* гарантирует, что все операции записи завершены;
* предотвращает чтение неинициализированных данных.

---

### 11. В чём преимущество shared memory версии по сравнению с atomic версией?

Преимущества:

* меньше атомарных операций в глобальной памяти;
* снижение конкуренции между потоками;
* более высокая производительность.

---

### 12. Какие ограничения накладывает использование shared memory?

Основные ограничения:

* ограниченный объём shared memory на блок;
* необходимость явной синхронизации;
* усложнение логики ядра.

---

### 13. Почему важно обнулять память на GPU перед запуском ядра?

Память, выделенная через `cudaMalloc`, не инициализируется автоматически.
Если её не обнулить, в бинах могут находиться случайные значения, что приводит к некорректному результату.

---

### 14. Как проверяется корректность работы параллельной гистограммы?

Корректность проверяется суммой всех бинов:

```
Σ histogram[i] = N
```

где `N` — количество элементов входного массива.

---

### 15. В каких случаях GPU-реализация будет значительно быстрее CPU?

GPU показывает наибольшее ускорение, когда:

* объём данных большой;
* вычисления хорошо параллелизуются;
* минимизировано количество синхронизаций и атомарных операций;
* используется shared memory и оптимальная конфигурация блоков.

